#!/usr/bin/env python

import rospy
import gym
from gym.utils import seeding
from plen_ros.gazebo_connection import GazeboConnection
from plen_ros.controllers_connection import ControllersConnection
from openai_ros.msg import RLExperimentInfo
import numpy as np
import os

#https://bitbucket.org/theconstructcore/theconstruct_msgs/src/master/msg/RLExperimentInfo.msg
# from openai_ros.msg import RLExperimentInfo - CHANGE THIS TO NORMAL MESSAGE IMPORT


# https://github.com/openai/gym/blob/master/gym/core.py
class RobotGazeboEnv(gym.Env):
    def __init__(self,
                 controllers_list,
                 robot_name_space,
                 init_config,
                 reset_controls,
                 start_init_physics_parameters=True,
                 reset_world_or_sim="SIMULATION"):

        # To reset Simulations
        rospy.logdebug("START init RobotGazeboEnv")
        self.gazebo = GazeboConnection(start_init_physics_parameters,
                                       reset_world_or_sim, robot_name_space,
                                       controllers_list, init_config)
        # self.gazebo.pauseSim()

        self.gazebo_sim = GazeboConnection(start_init_physics_parameters,
                                           "SIMULATION", robot_name_space,
                                           controllers_list, init_config)
        # controllers_list.append("joint_trajectory_controller")
        # controllers_list.append("joint_state_controller")
        self.controllers_object = ControllersConnection(
            namespace=robot_name_space, controllers_list=controllers_list)
        self.reset_controls = reset_controls
        self.seed()

        # Set up ROS related variables
        self.episode_num = 0
        self.cumulated_episode_reward = 0
        self.reward_pub = rospy.Publisher('/' + self.robot_name_space +
                                          '/reward',
                                          RLExperimentInfo,
                                          queue_size=1)

        # Set up init robot pose for spawn
        self.init_config = init_config

        # Set up robot URDF for spawn
        # Find abs path to this file
        dir_path = os.path.abspath(os.path.dirname(__file__))
        xacro_path = os.path.join(
            dir_path, "../../urdf/" + self.robot_name_space + ".urdf.xacro")
        result = os.popen("rosrun xacro xacro " + xacro_path)
        self.xml = result.read()

        # rospy.logwarn("RESPAWNING")
        # self.gazebo.unpauseSim()
        # self.respawn()

        # We Unpause the simulation and reset the controllers if needed
        """
        To check any topic we need to have the simulations running, we need to do two things:
        1) Unpause the simulation: without that th stream of data doesnt flow. This is for simulations
        that are pause for whatever the reason
        2) If the simulation was running already for some reason, we need to reset the controlers.
        This has to do with the fact that some plugins with tf, dont understand the reset of the simulation
        and need to be reseted to work properly.
        """
        # self.gazebo.unpauseSim()
        # if self.reset_controls:
        #     self.controllers_object.reset_controllers()

        rospy.logdebug("END init RobotGazeboEnv")

    # Env methods
    def respawn(self):

        # Unpause Sim
        self.gazebo.unpauseSim()

        # Unload Ctrl
        rospy.logwarn("UNLOADING CTRL")
        self.controllers_object.unload_controllers()

        # Delete Model
        rospy.logwarn("DELETING MODEL")
        self.gazebo.delete_model(self.robot_name_space)

        # Spawn Model
        rospy.logwarn("SPAWNING MODEL")
        self.gazebo.spawn_model(self.robot_name_space, self.xml, "",
                                self.init_config, "world")
        # Stop Gravity
        self.gazebo.change_gravity(0, 0, 0)

        # Load Ctrl
        rospy.logwarn("LOADING CTRL")
        self.controllers_object.load_controllers()

        # Start Gravity
        self.gazebo.change_gravity(0, 0, -9.81)

    def seed(self, seed=None):
        self.np_random, seed = seeding.np_random(seed)
        return [seed]

    def step(self, action):
        """
        Function executed each time step.
        Here we get the action execute it in a time step and retrieve the
        observations generated by that action.
        :param action:
        :return: obs, reward, done, info
        """
        """
        Here we should convert the action num to movement action, execute the action in the
        simulation and get the observations result of performing that action.
        """
        rospy.logdebug("START STEP OpenAIROS")

        self.gazebo.unpauseSim()
        self._set_action(action)
        self.gazebo.pauseSim()
        obs = self._get_obs()
        done = self._is_done(obs)
        info = {}
        reward = self._compute_reward(obs, done)
        self.cumulated_episode_reward += reward

        rospy.logdebug("END STEP OpenAIROS")

        return obs, reward, done, info

    def reset(self):
        rospy.logdebug("Reseting RobotGazeboEnvironment")
        self._reset_sim()
        self._init_env_variables()
        self._update_episode()
        obs = self._get_obs()
        rospy.logdebug("END Reseting RobotGazeboEnvironment")
        return obs

    def close(self):
        """
        Function executed when closing the environment.
        Use it for closing GUIS and other systems that need closing.
        :return:
        """
        rospy.logdebug("Closing RobotGazeboEnvironment")
        rospy.signal_shutdown("Closing RobotGazeboEnvironment")

    def _update_episode(self):
        """
        Publishes the cumulated reward of the episode and
        increases the episode number by one.
        :return:
        """
        rospy.logdebug("PUBLISHING REWARD...")
        self._publish_reward_topic(self.cumulated_episode_reward,
                                   self.episode_num)
        rospy.logwarn("EPISODE REWARD = " +
                      str(self.cumulated_episode_reward) + ", EP = " +
                      str(self.episode_num))

        self.episode_num += 1
        self.cumulated_episode_reward = 0

    def _publish_reward_topic(self, reward, episode_number=1):
        """
        This function publishes the given reward in the reward topic for
        easy access from ROS infrastructure.
        :param reward:
        :param episode_number:
        :return:
        """
        reward_msg = RLExperimentInfo()
        reward_msg.episode_number = episode_number
        reward_msg.episode_reward = reward
        self.reward_pub.publish(reward_msg)

        # Sometimes after 9999+ resets, gazebo has problems.
        # so we try a simulation reset
        # if np.isnan(reward):
        #     rospy.logerr("---------------------------------------")
        #     rospy.logerr("nan DETECTED, RESPAWNING!")
        #     self.gazebo.pauseSim()
        #     self.respawn()
        #     self._check_all_systems_ready()
        #     self.gazebo.unpauseSim()
        #     self._set_init_pose()
        #     rospy.sleep(0.5)
        #     self.gazebo.pauseSim()
        #     # Reset Sim to try and remove nan
        #     self.gazebo.resetSim()
        #     self.gazebo.unpauseSim()
        #     self.controllers_object.reset_controllers()
        #     self._check_all_systems_ready()
        #     self.gazebo.pauseSim()

    # Extension methods
    # ----------------------------

    def _reset_sim(self):
        """Resets a simulation
        """
        rospy.loginfo("---------------------------------------")
        rospy.logerr("RESETTING")
        if self.reset_controls:
            rospy.logdebug("RESET CONTROLLERS")
            self.gazebo.unpauseSim()
            self.controllers_object.reset_controllers()
            # self._check_all_systems_ready()
            self._set_init_pose()
            rospy.sleep(0.5)
            self.gazebo.resetSim()
            self.controllers_object.reset_controllers()
            self._check_all_systems_ready()
            self.gazebo.pauseSim()
            """
            rospy.logdebug("RESET CONTROLLERS")
            self.gazebo.unpauseSim()
            self.controllers_object.switch_controllers(
                controllers_on=[],
                controllers_off=self.controllers_object.controllers_list)
            self.gazebo.pauseSim()
            self.gazebo.reset_joints(self.controllers_object.controllers_list,
                                     self.robot_name_space)
            self.gazebo.unpauseSim()
            self._check_all_systems_ready()
            self.gazebo.pauseSim()
            self.gazebo.resetSim()
            self.gazebo.unpauseSim()
            self.controllers_object.switch_controllers(
                controllers_on=self.controllers_object.controllers_list,
                controllers_off=[])
            self._check_all_systems_ready()
            self._set_init_pose()
            self.gazebo.pauseSim()
            """

        else:
            rospy.logwarn("DONT RESET CONTROLLERS")
            # Unpause
            self.gazebo.unpauseSim()
            # Check Controllers/Sensors
            self._check_all_systems_ready()
            # Set Joints to Init
            self._set_init_pose()
            rospy.sleep(0.5)
            # Pause
            self.gazebo.pauseSim()
            # Reset Pose or Sim (see input to GazeboConnection)
            self.gazebo.reset_pose()
            # self.gazebo.resetSim()
            # Unpause
            self.gazebo.unpauseSim()
            # Check Controllers/Sensors
            self._check_all_systems_ready()
            # Pause
            self.gazebo.pauseSim()

        rospy.logdebug("RESET SIM END")
        return True

    def _set_init_pose(self):
        """Sets the Robot in its init pose
        """
        raise NotImplementedError()

    def _check_all_systems_ready(self):
        """
        Checks that all the sensors, publishers and other simulation systems are
        operational.
        """
        raise NotImplementedError()

    def _get_obs(self):
        """Returns the observation.
        """
        raise NotImplementedError()

    def _init_env_variables(self):
        """Inits variables needed to be initialised each time we reset at the start
        of an episode.
        """
        raise NotImplementedError()

    def _set_action(self, action):
        """Applies the given action to the simulation.
        """
        raise NotImplementedError()

    def _is_done(self, observations):
        """Indicates whether or not the episode is done ( the robot has fallen for example).
        """
        raise NotImplementedError()

    def _compute_reward(self, observations, done):
        """Calculates the reward to give based on the observations given.
        """
        raise NotImplementedError()

    def _env_setup(self, initial_qpos):
        """Initial configuration of the environment. Can be used to configure initial state
        and extract information from the simulation.
        """
        raise NotImplementedError()
